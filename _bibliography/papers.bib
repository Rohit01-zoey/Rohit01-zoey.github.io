---
---

@inproceedings{paruchuri2025whats,
  title     = {"What's Up, Doc?": Analyzing How Users Seek Health Information in Large-Scale Conversational {AI} Datasets},
  author    = {Paruchuri, Akshay and Aziz, Maryam and Vartak, Rohit and Ali, Ayman and Uchehara, Best and Liu, Xin and Chatterjee, Ishan and Agrawal, Monica},
  editor    = {Christodoulopoulos, Christos and Chakraborty, Tanmoy and Rose, Carolyn and Peng, Violet},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2025},
  month     = {nov},
  year      = {2025},
  address   = {Suzhou, China},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2025.findings-emnlp.125/},
  doi       = {10.18653/v1/2025.findings-emnlp.125},
  pages     = {2312--2336},
  isbn      = {979-8-89176-335-7},
  preview   = {healthchat_img.png},
  abstract  = {People are increasingly seeking healthcare information from large language models (LLMs) via interactive chatbots, yet the nature and inherent risks of these conversations remain largely unexplored. In this paper, we filter large-scale conversational AI datasets to achieve HealthChat-11K, a curated dataset of 11K real-world conversations composed of 25K user messages. We use HealthChat-11K and a clinician-driven taxonomy for how users interact with LLMs when seeking healthcare information in order to systematically study user interactions across 21 distinct health specialties. Our analysis reveals insights into the nature of how and why users seek health information, such as common interactions, instances of incomplete context, affective behaviors, and interactions (e.g., leading questions) that can induce sycophancy, underscoring the need for improvements in the healthcare support capabilities of LLMs deployed as conversational AI. We release code and artifacts to retrieve our analyses and combine them into a curated dataset for further research.}
}

@article{singhal2025abba,
  title         = {ABBA-Adapters: Efficient and Expressive Fine-Tuning of Foundation Models},
  author        = {Singhal*, Raghav and Ponkshe*, Kaustubh and Vartak*, Rohit and Vepakomma, Praneeth},
  journal       = {arXiv preprint arXiv:2505.14238},
  year          = {2025},
  eprint        = {2505.14238},
  archivePrefix = {arXiv},
  primaryClass  = {cs.CL},
  url           = {https://arxiv.org/abs/2505.14238},
  preview       = {abba_img.png},
  google_scholar_id = {d1gkVwhDpl0C},
  selected      = {true},
  additional_info  = {*Spotlight at ES-FOMO@ICML 2025, Accepted at ICLR 2026*}
}

