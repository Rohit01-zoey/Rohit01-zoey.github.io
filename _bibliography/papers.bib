---
---

@inproceedings{paruchuri2025whats,
  title     = {"What's Up, Doc?": Analyzing How Users Seek Health Information in Large-Scale Conversational {AI} Datasets},
  author    = {Paruchuri, Akshay and Aziz, Maryam and Vartak, Rohit and Ali, Ayman and Uchehara, Best and Liu, Xin and Chatterjee, Ishan and Agrawal, Monica},
  editor    = {Christodoulopoulos, Christos and Chakraborty, Tanmoy and Rose, Carolyn and Peng, Violet},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2025},
  month     = {nov},
  year      = {2025},
  address   = {Suzhou, China},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2025.findings-emnlp.125/},
  doi       = {10.18653/v1/2025.findings-emnlp.125},
  pages     = {2312--2336},
  isbn      = {979-8-89176-335-7},
  preview   = {healthchat_img.png},
  google_scholar_id = {2osOgNQ5qMEC},
  abstract  = {People are increasingly seeking healthcare information from large language models (LLMs) via interactive chatbots, yet the nature and inherent risks of these conversations remain largely unexplored. In this paper, we filter large-scale conversational AI datasets to achieve HealthChat-11K, a curated dataset of 11K real-world conversations composed of 25K user messages. We use HealthChat-11K and a clinician-driven taxonomy for how users interact with LLMs when seeking healthcare information in order to systematically study user interactions across 21 distinct health specialties. Our analysis reveals insights into the nature of how and why users seek health information, such as common interactions, instances of incomplete context, affective behaviors, and interactions (e.g., leading questions) that can induce sycophancy, underscoring the need for improvements in the healthcare support capabilities of LLMs deployed as conversational AI. We release code and artifacts to retrieve our analyses and combine them into a curated dataset for further research.}
}

@article{singhal2025abba,
  title         = {ABBA-Adapters: Efficient and Expressive Fine-Tuning of Foundation Models},
  author        = {Singhal*, Raghav and Ponkshe*, Kaustubh and Vartak*, Rohit and Vepakomma, Praneeth},
  journal       = {arXiv preprint arXiv:2505.14238},
  year          = {2025},
  eprint        = {2505.14238},
  archivePrefix = {arXiv},
  primaryClass  = {cs.CL},
  url           = {https://arxiv.org/abs/2505.14238},
  preview       = {abba_img.png},
  google_scholar_id = {d1gkVwhDpl0C},
  selected      = {true},
  additional_info  = {*Spotlight at ES-FOMO@ICML 2025, Accepted at ICLR 2026*}
}

@article{singhal2025fedsb,
  title            = {Fed-SB: A Silver Bullet for Extreme Communication Efficiency and Performance in (Private) Federated LoRA Fine-Tuning},
  author           = {Singhal*, Raghav and Ponkshe*, Kaustubh and Vartak, Rohit and Varshney, Lav R. and Vepakomma, Praneeth},
  journal          = {arXiv preprint arXiv:2502.15436},
  year             = {2025},
  eprint           = {2502.15436},
  archivePrefix    = {arXiv},
  primaryClass     = {cs.LG},
  url              = {https://arxiv.org/abs/2502.15436},
  preview          = {fedsb_img.png},
  google_scholar_id = {u5HHmVD_uO8C},
  selected         = {true},
  additional_info  = {*Accepted at ES-FOMO@ICML 2025*}
}

@inproceedings{vartak2023robustness,
  author    = {Vartak, Rohit K. and Saraswat, Vivek and Ganguly, Udayan},
  editor    = {Iliadis, Lazaros and Papaleonidas, Antonios and Angelov, Plamen and Jayne, Chrisina},
  title     = {Robustness to Variability and Asymmetry of In-Memory On-Chip Training},
  booktitle = {Artificial Neural Networks and Machine Learning -- ICANN 2023},
  year      = {2023},
  publisher = {Springer Nature Switzerland},
  address   = {Cham},
  pages     = {249--257},
  isbn      = {978-3-031-44201-8},
  abstract  = {In-memory on-chip learning is crucial for low-power, in-field training capabilities at the edge. We demonstrate the robustness of on-chip back-propagation to hardware variability in terms of bit-cell transistor $V_T$ variability ($2.5\times$ more robust than off-chip training). We use perturbation schemes, asymmetry variations and variability-aware update schemes to identify the relative contribution of different on-chip operations: forward pass, backward pass and weight updates to Fashion-MNIST classification performance degradation with variations. It is revealed that variability during the weight update step is crucial while accuracy of backward pass or gradient calculation is not critical. We promote weight perturbation scheme over back-propagation as the choice for on-chip in-memory training with reduced points of failure and low cost of hardware.}
}