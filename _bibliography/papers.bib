---
---

@InProceedings{10.1007/978-3-031-44201-8_21,
author="K. Vartak, Rohit
and Saraswat, Vivek
and Ganguly, Udayan",
editor="Iliadis, Lazaros
and Papaleonidas, Antonios
and Angelov, Plamen
and Jayne, Chrisina",
title="Robustness to Variability and Asymmetry of In-Memory On-Chip Training",
booktitle="Artificial Neural Networks and Machine Learning -- ICANN 2023",
year="2023",
publisher="Springer Nature Switzerland",
address="Cham",
pages="249--257",
abstract="In-memory on-chip learning is crucial for low-power, in-field training capabilities at the edge. We demonstrate the robustness of on-chip back-propagation to hardware variability in terms of bit-cell transistor {\$}{\$}V{\_}T{\$}{\$}variability ({\$}{\$}2.5{\backslash}times {\$}{\$}more robust than off-chip training). We use perturbation schemes, asymmetry variations and variability-aware update schemes to identify the relative contribution of different on-chip operations: forward pass, backward pass and weight updates to Fashion-MNIST classification performance degradation with variations. It is revealed that variability during the weight update step is crucial while accuracy of backward pass or gradient calculation is not critical. We promote weight perturbation scheme over back-propagation as the choice for on-chip in-memory training with reduced points of failure and low cost of hardware.",
isbn="978-3-031-44201-8"
}
